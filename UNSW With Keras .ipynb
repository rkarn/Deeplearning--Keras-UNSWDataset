{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n",
      "('Trainset size: ', (175341, 43), (175341,), 'Testset size: ', (82332, 43), (82332,))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "import sklearn\n",
    "\n",
    "# Read in the training CSV file\n",
    "print \"Reading Training csv file.\"\n",
    "df1 = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "df1.drop('label', axis=1, inplace=True)\n",
    "\n",
    "#One hot encoding the string variables\n",
    "obj_df1=df1\n",
    "obj_df1[\"proto\"] = obj_df1[\"proto\"].astype('category')\n",
    "obj_df1[\"service\"] = obj_df1[\"service\"].astype('category')\n",
    "obj_df1[\"state\"] = obj_df1[\"state\"].astype('category')\n",
    "obj_df1[\"proto_cat\"] = obj_df1[\"proto\"].cat.codes\n",
    "obj_df1[\"service_cat\"] = obj_df1[\"service\"].cat.codes\n",
    "obj_df1[\"state_cat\"] = obj_df1[\"state\"].cat.codes\n",
    "\n",
    "obj_df1[\"proto\"] = obj_df1[\"proto_cat\"]\n",
    "obj_df1[\"service\"] = obj_df1[\"service_cat\"]\n",
    "obj_df1[\"state\"] = obj_df1[\"state_cat\"]\n",
    "\n",
    "obj_df1.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df1.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df1.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_train_all_attacks = obj_df1[\"attack_cat\"]\n",
    "X_train = obj_df1.values[:,:-1]\n",
    "\n",
    "#Normalizing train set\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i,j] = round(X_train[i,j]/maximum,3)\n",
    "\n",
    "#Make a catagorical cloumn for each type of label in trainset\n",
    "obj_df1=pd.get_dummies(obj_df1, columns=[\"attack_cat\"])\n",
    "Y_train_each_attach = obj_df1.values[:,-10:]\n",
    "        \n",
    "# Read in the testing CSV file \n",
    "print \"Reading Testing csv file.\"\n",
    "df2 = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "df2.drop('label', axis=1, inplace=True)\n",
    "\n",
    "#One hot encoding the string variables\n",
    "obj_df2=df2\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto\"].astype('category')\n",
    "obj_df2[\"service\"] = obj_df2[\"service\"].astype('category')\n",
    "obj_df2[\"state\"] = obj_df2[\"state\"].astype('category')\n",
    "obj_df2[\"proto_cat\"] = obj_df2[\"proto\"].cat.codes\n",
    "obj_df2[\"service_cat\"] = obj_df2[\"service\"].cat.codes\n",
    "obj_df2[\"state_cat\"] = obj_df2[\"state\"].cat.codes\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto_cat\"]\n",
    "obj_df2[\"service\"] = obj_df2[\"service_cat\"]\n",
    "obj_df2[\"state\"] = obj_df2[\"state_cat\"]\n",
    "\n",
    "obj_df2.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "Y_test_all_attacks = obj_df2[\"attack_cat\"]\n",
    "X_test = obj_df2.values[:,:-1]\n",
    "\n",
    "#Normalizing test set\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i,j] = round(X_test[i,j]/maximum,3)\n",
    "        \n",
    "#Make a catagorical cloumn for each type of label in testset\n",
    "obj_df2=pd.get_dummies(obj_df2, columns=[\"attack_cat\"])\n",
    "Y_test_each_attach = obj_df2.values[:,-10:]\n",
    "\n",
    "cleanup_nums = {\"Worms\":0, \"Shellcode\":1, \"Reconnaissance\":2, \"Normal\":3, \"Generic\":4, \"Fuzzers\":5, \"Exploits\":6, \"DoS\":7, \"Backdoor\":8, \"Analysis\":9}\n",
    "Y_train_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "Y_test_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "print('Trainset size: ',X_train.shape,Y_train_all_attacks.shape,'Testset size: ',X_test.shape,Y_test_all_attacks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Attack:', 'Analysis')\n",
      "Train Results: 98.88% (0.00%)\n",
      "Test Results: 99.18% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Backdoor')\n",
      "Train Results: 99.93% (0.00%)\n",
      "Test Results: 99.95% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'DoS')\n",
      "Train Results: 99.35% (0.00%)\n",
      "Test Results: 99.54% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Exploits')\n",
      "Train Results: 94.00% (0.02%)\n",
      "Test Results: 95.75% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Fuzzers')\n",
      "Train Results: 92.31% (0.02%)\n",
      "Test Results: 55.85% (9.81%)\n",
      "-----------------\n",
      "('Attack:', 'Generic')\n",
      "Train Results: 97.30% (0.04%)\n",
      "Test Results: 77.08% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Normal')\n",
      "Train Results: 89.99% (0.03%)\n",
      "Test Results: 92.64% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Reconnaissance')\n",
      "Train Results: 85.11% (0.35%)\n",
      "Test Results: 86.48% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Shellcode')\n",
      "Train Results: 93.00% (0.00%)\n",
      "Test Results: 95.03% (0.00%)\n",
      "-----------------\n",
      "('Attack:', 'Worms')\n",
      "Train Results: 99.00% (0.00%)\n",
      "Test Results: 99.29% (0.00%)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "#Binary classification for each attack-type\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Model for binary classification\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=43, kernel_initializer='random_uniform', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='random_uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='random_uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "attack_name = obj_df1.columns[-10:]\n",
    "model_weights_save = []\n",
    "# evaluate model with standardized dataset\n",
    "for attack_type in range(len(attack_name)):\n",
    "    Y_train = Y_train_each_attach[:,-attack_type]\n",
    "    Y_test = Y_test_each_attach[:,-attack_type]\n",
    "    estimator = KerasClassifier(build_fn=create_baseline, batch_size=100, verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print('Attack:',attack_name[attack_type].split('_')[-1])\n",
    "    print(\"Train Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "    results = cross_val_score(estimator, X_test, Y_test, cv=kfold)\n",
    "    print(\"Test Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_178 (Dense)            (None, 60)                2640      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 6,910\n",
      "Trainable params: 6,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train Results: 70.83% (0.04%)\n",
      "Test Results: 44.94% (0.00%) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Multilabel classification\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import keras.initializers\n",
    "\n",
    "hidden_units = 100\n",
    "\n",
    "# Model for multiclass classification\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    keras.initializers.he_normal(seed=None)\n",
    "    model.add(Dense(60, input_dim=43,  activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(60,  activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10,  activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "print(create_baseline().summary())\n",
    "estimator = KerasClassifier(build_fn=create_baseline, batch_size=100, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X_train, Y_train_all_attacks, cv=kfold)\n",
    "print(\"Train Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "results = cross_val_score(estimator, X_test, Y_test_all_attacks, cv=kfold)\n",
    "print(\"Test Results: %.2f%% (%.2f%%) \\n\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
